# Clustering Projects
## What is clustering?
	 It is basically a type of unsupervised learning method.
     An unsupervised learning method is a method in which we draw references
     from datasets consisting of input data without labeled responses.
     Generally, it is used as a process to find meaningful structure, explanatory
     underlying processes, generative features, and groupings inherent in a set of
     examples.
     
	Clustering is the task of dividing the population or data points into 
    a number of groups such that data points in the same groups are more similar
    to other data points in the same group and dissimilar to the data points 
    in other groups. It is basically a collection of objects on the basis of
    similarity and dissimilarity between them. 
 ## Why Clustering?
 		Clustering is very much important as it determines the intrinsic grouping among
    the unlabeled data present. There are no criteria for a good clustering. 
    	It depends on the user, what is the criteria they may use which satisfy their need. 
    For instance, we could be interested in finding representatives for homogeneous
    groups (data reduction), in finding “natural clusters” and describe their unknown
    properties (“natural” data types), in finding useful and suitable groupings
    (“useful” data classes) or in finding unusual data objects (outlier detection).
    This algorithm must make some assumptions which constitute the similarity of
    points and each assumption make different and equally valid clusters.

Clustering Methods :
    
## What are the Clustering projects included in this repositry?

### 1.Logistic Regression Classification 
	PROJECT NAME   : "CLUSTER ANALYSIS OF STOCKS USING K-mean Algorithm"
    DATASET NAME   : "Sample_Stocks.Csv"
    DATASET SOURCE : "Kaggle Sample_stocks.csv"
### 2.K-Nearest Neighbour's Classification
	PROJECT NAME   : "CLUSTER ANALYSIS OF STOCKS USING HEIRARCHICAL CLUSTERING"
    DATASET NAME   : "Sample_Stocks.Csv"
    DATASET SOURCE : "Kaggle Sample_stocks.csv"

    
## Roadmap

+++++++++++++A STAR IS APPRECIATED++++++++++++++

Before we jump right into programming, we should lay out a brief guide to keep us on track. The following steps form the basis for any machine learning workflow once we have a problem and model in mind :

    1.State the question and determine required data
    2.Acquire the data in an accessible format
    3.Identify and correct missing data points/anomalies as required
    4.Prepare the data for the machine learning model
    5.Establish a baseline model that you aim to exceed
    6.Train the model on the training data
    7.Make predictions on the test data
    8.Compare predictions to the known test set targets and calculate performance metrics
    9.If performance is not satisfactory, adjust the model, acquire more data, or try a different modeling technique
    10.Interpret model and report results visually and numerically
    ///THESE ARE THE STEPS I FOLLOW WHILE WORKING ON A PROBLEM
    















